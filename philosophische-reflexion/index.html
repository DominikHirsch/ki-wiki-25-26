<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/ki-wiki-25-26/assets/css/main.css">
<!-- Font Awesome für Icons (z. B. Such-Icon) -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/ki-wiki-25-26/">
          ki-wiki
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="https://mmistakes.github.io/minimal-mistakes/docs/quick-start-guide/">Quick-Start Guide</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  <div class="sidebar sticky">
    <nav class="nav__list">
        <input id="ac-toc" name="accordion-toc" type="checkbox">
        <label for="ac-toc">Toggle Menu</label>
        <ul class="nav__items">
            
            
            <li>
                <a href="/ki-wiki-25-26/">
                    <span class="nav__sub-title">Startseite</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/ki-geschichte/">
                    <span class="nav__sub-title">ki-geschichte</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/prompt_engineering/">
                    <span class="nav__sub-title">Prompt Engineering</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/seite2/">
                    <span class="nav__sub-title">Seite 2</span>
                </a>
                
                <ul>
    
    <li>
        <a href="/ki-wiki-25-26/seite2/sub1/">Unterseite 1</a>
        
    </li>
    
    <li>
        <a href="/ki-wiki-25-26/seite2/sub2/">Unterseite 2</a>
        
    </li>
    
</ul>

                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/Soziologische_Perspektive/">
                    <span class="nav__sub-title">Soziologische Perspektive</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/ki_heute_complete/">
                    <span class="nav__sub-title">Künstliche Intelligenz heute</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/rechtlicher-rahmen/">
                    <span class="nav__sub-title">rechtlicher-rahmen</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/anwendung-schule/">
                    <span class="nav__sub-title">anwendung-schule</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/psychologische_perspektiven/">
                    <span class="nav__sub-title">psychologische-perspektiven</span>
                </a>
                
            </li>
            
            <li>
                <a href="/ki-wiki-25-26/philosophische-reflexion/">
                    <span class="nav__sub-title">Philosophische-reflexion</span>
                </a>
                
            </li>
            
        </ul>
    </nav>
</div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Philosophische-reflexion">
    <meta itemprop="description" content="Künstliche Intelligenz in der Bildung: Eine systematische ethisch-philosophische Analyse">
    <meta itemprop="datePublished" content="2025-11-26T10:08:03+00:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Philosophische-reflexion
</h1>
          


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Inhalt</h4></header>
              <ul class="toc__menu"><li><a href="#künstliche-intelligenz-in-der-bildung-eine-systematische-ethisch-philosophische-analyse">Künstliche Intelligenz in der Bildung: Eine systematische ethisch-philosophische Analyse</a><ul><li><a href="#1-einleitung-ki-in-der-bildung-als-normatives-spannungsfeld">1. Einleitung: KI in der Bildung als normatives Spannungsfeld</a></li><li><a href="#2-deontologie-ki-zwischen-pflicht-gutem-willen-und-struktureller-verantwortung">2. Deontologie: KI zwischen Pflicht, gutem Willen und struktureller Verantwortung</a><ul><li><a href="#21-kants-kategorischer-imperativ-und-die-problematik-der-algorithmenethik">2.1 Kants kategorischer Imperativ und die Problematik der Algorithmenethik</a><ul><li><a href="#211-autonomie-vs-algorithmische-steuerung">2.1.1 Autonomie vs. algorithmische Steuerung</a></li><li><a href="#212-der-gute-wille-in-der-ki-entwicklung">2.1.2 Der gute Wille in der KI-Entwicklung</a></li><li><a href="#213-strukturelle-verantwortung-und-das-problem-der-vielen-hände">2.1.3 Strukturelle Verantwortung und das „Problem der vielen Hände“</a></li></ul></li><li><a href="#22-praktische-implikationen-ein-deontologischer-rahmen-für-ki-in-schulen">2.2 Praktische Implikationen: Ein deontologischer Rahmen für KI in Schulen</a></li></ul></li><li><a href="#3-tugendethik-ki-und-die-kultivierung-menschlicher-exzellenz">3. Tugendethik: KI und die Kultivierung menschlicher Exzellenz</a><ul><li><a href="#31-aristoteles-tugendethik-im-digitalen-zeitalter">3.1 Aristoteles’ Tugendethik im digitalen Zeitalter</a><ul><li><a href="#311-die-tugend-der-phronesis-klugheit-in-algorithmischen-umgebungen">3.1.1 Die Tugend der phronesis (Klugheit) in algorithmischen Umgebungen</a></li><li><a href="#312-ki-und-die-tugend-der-neugier">3.1.2 KI und die Tugend der Neugier</a></li><li><a href="#313-soziale-tugenden-in-hybrid-sozialen-lernumgebungen">3.1.3 Soziale Tugenden in hybrid-sozialen Lernumgebungen</a></li></ul></li><li><a href="#32-ki-als-tugend-trainer-möglichkeiten-und-grenzen">3.2 KI als „Tugend-Trainer“? Möglichkeiten und Grenzen</a></li></ul></li><li><a href="#4-utilitarismus-nutzenmaximierung-zwischen-effizienz-und-gerechtigkeit">4. Utilitarismus: Nutzenmaximierung zwischen Effizienz und Gerechtigkeit</a><ul><li><a href="#41-quantitativer-utilitarismus-ki-als-heilsbringer-der-bildung">4.1 Quantitativer Utilitarismus: KI als Heilsbringer der Bildung?</a><ul><li><a href="#411-das-trolley-problem-der-bildungs-ki">4.1.1 Das „Trolley-Problem“ der Bildungs-KI</a></li></ul></li><li><a href="#42-qualitativer-utilitarismus-bildung-als-mehr-als-messbare-outcomes">4.2 Qualitativer Utilitarismus: Bildung als mehr als messbare Outcomes</a></li><li><a href="#43-utilitarismus-in-der-praxis-wer-profitiert-wirklich">4.3 Utilitarismus in der Praxis: Wer profitiert wirklich?</a></li></ul></li><li><a href="#5-synthese-ein-pluriperspektivischer-ethischer-rahmen-für-ki-in-der-bildung">5. Synthese: Ein pluriperspektivischer ethischer Rahmen für KI in der Bildung</a></li><li><a href="#6-fazit-ki-in-der-bildung-als-gesellschaftliche-gestaltungsaufgabe">6. Fazit: KI in der Bildung als gesellschaftliche Gestaltungsaufgabe</a><ul><li><a href="#61-drei-dringende-handlungsfelder">6.1 Drei dringende Handlungsfelder</a></li><li><a href="#62-offene-forschungsfragen">6.2 Offene Forschungsfragen</a></li><li><a href="#63-provokante-these-zur-diskussion">6.3 Provokante These zur Diskussion</a></li><li><a href="#diskussionsfragen-für-leserinnen">Diskussionsfragen für Leser:innen</a></li></ul></li></ul></li></ul>

            </nav>
          </aside>
        
        <h1 id="künstliche-intelligenz-in-der-bildung-eine-systematische-ethisch-philosophische-analyse">Künstliche Intelligenz in der Bildung: Eine systematische ethisch-philosophische Analyse</h1>

<hr />
<h2 id="1-einleitung-ki-in-der-bildung-als-normatives-spannungsfeld"><strong>1. Einleitung: KI in der Bildung als normatives Spannungsfeld</strong></h2>
<p>Die Integration von KI-Systemen in Bildungsprozesse wirft nicht nur technische, sondern <strong>grundlegende anthropologische und ethische Fragen</strong> auf (Biesta, 2022; Selwyn, 2019). Drei Dimensionen sind dabei zentral:</p>
<ol>
  <li><strong>Epistemologisch:</strong> Verändert KI unser Verständnis von Wissen und Lernen?</li>
  <li><strong>Ethisch:</strong> Welche moralischen Prinzipien müssen bei der Gestaltung von KI-Bildungstools berücksichtigt werden?</li>
  <li><strong>Politisch:</strong> Wer entscheidet über den Einsatz von KI in Schulen – und nach welchen Kriterien?</li>
</ol>

<p>Dieser Artikel analysiert die <strong>deontologische</strong>, <strong>tugendethische</strong> und <strong>utilitaristische</strong> Perspektive unter Einbezug aktueller empirischer Studien und philosophischer Grundlagentexte. Ein besonderer Fokus liegt auf der <strong>Kantischen Konzeption des guten Willens</strong>, der <strong>Aristotelischen Tugendethik in digitalen Kontexten</strong> sowie der <strong>utilitaristischen Nutzenabwägung</strong> im Bildungssektor.</p>

<hr />

<h2 id="2-deontologie-ki-zwischen-pflicht-gutem-willen-und-struktureller-verantwortung"><strong>2. Deontologie: KI zwischen Pflicht, gutem Willen und struktureller Verantwortung</strong></h2>

<h3 id="21-kants-kategorischer-imperativ-und-die-problematik-der-algorithmenethik"><strong>2.1 Kants kategorischer Imperativ und die Problematik der Algorithmenethik</strong></h3>
<p>Kants Ethik (1785/1999) fordert, dass Handlungen <strong>universalisierbar</strong> sein müssen und die <strong>Würde des Menschen</strong> als Zweck an sich respektieren. Für KI in der Bildung ergeben sich daraus drei normative Herausforderungen:</p>

<h4 id="211-autonomie-vs-algorithmische-steuerung"><strong>2.1.1 Autonomie vs. algorithmische Steuerung</strong></h4>
<ul>
  <li><strong>Problem:</strong> Adaptive Lernsysteme (z. B. <em>ALEKS</em>, <em>Squirrel AI</em>) treffen Entscheidungen über Lerninhalte, die traditionell im <strong>pädagogischen Ermessen</strong> von Lehrkräften liegen.</li>
  <li><strong>Philosophische Einordnung:</strong>
    <ul>
      <li>Kant betont, dass Aufklärung „der Ausgang des Menschen aus seiner selbstverschuldeten Unmündigkeit“ sei (<em>Beantwortung der Frage: Was ist Aufklärung?</em>, 1784). KI-Systeme, die Lernpfade vorgeben, riskieren eine <strong>neue Form der Unmündigkeit</strong> (Zuboff, 2019).</li>
      <li><strong>Gegenargument (Kompatibilismus):</strong> Proponenten wie Floridi (2019) argumentieren, dass KI die Autonomie sogar stärken kann, indem sie <strong>individuelle Lernbedürfnisse</strong> besser erkennt als standardisierte Lehrpläne.</li>
    </ul>
  </li>
  <li><strong>Empirische Evidenz:</strong>
    <ul>
      <li>Studien zeigen, dass Lernende, die mit KI-Systemen arbeiten, seltener <strong>metakognitive Strategien</strong> entwickeln (Azevedo et al., 2020).</li>
      <li><strong>Lösungsansatz:</strong> „Explainable AI“ (XAI) könnte Transparenz herstellen – doch selbst erklärbare Algorithmen werfen die Frage auf: <em>Wer erklärt die Erklärung?</em> (Burrell, 2016).</li>
    </ul>
  </li>
</ul>

<h4 id="212-der-gute-wille-in-der-ki-entwicklung"><strong>2.1.2 Der gute Wille in der KI-Entwicklung</strong></h4>
<ul>
  <li><strong>Kants Definition:</strong> „Ein guter Wille ist nicht durch seine Wirkung, sondern durch sein Wollen gut“ (<em>Grundlegung zur Metaphysik der Sitten</em>, AA IV, 394).</li>
  <li><strong>Anwendung auf KI:</strong>
    <ul>
      <li><strong>Entwickler</strong> müssen sicherstellen, dass KI-Systeme <strong>nicht instrumentalisierend</strong> wirken (z. B. durch datengetriebene Manipulation von Lernverhalten).</li>
      <li><strong>Schulen</strong> müssen KI aus <strong>pädagogischer Verantwortung</strong> einsetzen – nicht aus ökonomischen oder effizienzorientierten Motiven.</li>
      <li><strong>Kritik:</strong> In der Praxis dominieren oft <strong>utilitaristische Kosten-Nutzen-Abwägungen</strong> (z. B. Einsparung von Lehrpersonal), was dem Kantischen Prinzip widerspricht (Hagendorff, 2020).</li>
    </ul>
  </li>
</ul>

<h4 id="213-strukturelle-verantwortung-und-das-problem-der-vielen-hände"><strong>2.1.3 Strukturelle Verantwortung und das „Problem der vielen Hände“</strong></h4>
<ul>
  <li><strong>Dilemma:</strong> Wenn KI-Systeme diskriminieren (z. B. durch verzerrte Trainingsdaten), ist unklar, wer verantwortlich ist:
    <ul>
      <li>Die <strong>Entwickler</strong> (die den Algorithmus programmiert haben)?</li>
      <li>Die <strong>Schule</strong> (die das System einsetzt)?</li>
      <li>Die <strong>Politik</strong> (die den Rahmen setzt)?</li>
    </ul>
  </li>
  <li><strong>Lösungsvorschlag:</strong> Ein <strong>mehrstufiges Verantwortungsmodell</strong> nach Matthias (2004), das <strong>technische</strong>, <strong>organisatorische</strong> und <strong>rechtliche</strong> Verantwortungsebenen unterscheidet.</li>
</ul>

<table>
  <thead>
    <tr>
      <th><strong>Verantwortungsebene</strong></th>
      <th><strong>Akteur</strong></th>
      <th><strong>Normative Anforderung</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Mikroebene</td>
      <td>Lehrkräfte</td>
      <td>Kritische Reflexion des KI-Einsatzes im Unterricht</td>
    </tr>
    <tr>
      <td>Mesoebene</td>
      <td>Schulverwaltung</td>
      <td>Ethische Richtlinien und Fortbildungen</td>
    </tr>
    <tr>
      <td>Makroebene</td>
      <td>Bildungspolitik</td>
      <td>Regulatorische Rahmen für KI in Schulen</td>
    </tr>
    <tr>
      <td>Metaebene</td>
      <td>Tech-Unternehmen</td>
      <td>Algorithmen auf Bias und Fairness prüfen</td>
    </tr>
  </tbody>
</table>

<hr />
<h3 id="22-praktische-implikationen-ein-deontologischer-rahmen-für-ki-in-schulen"><strong>2.2 Praktische Implikationen: Ein deontologischer Rahmen für KI in Schulen</strong></h3>
<ol>
  <li><strong>Partizipative Gestaltung:</strong> Lernende und Lehrkräfte müssen in die Entwicklung von KI-Systemen einbezogen werden („Design Justice“, Costanza-Chock, 2020).</li>
  <li><strong>Recht auf Erklärung:</strong> Lernende haben ein <strong>moralisches Recht</strong> darauf, zu verstehen, wie KI-Entscheidungen zustande kommen (EU-KI-Verordnung, 2021, Art. 13).</li>
  <li><strong>Verbot manipulativer Systeme:</strong> KI darf nicht dazu verwendet werden, Lernende durch <strong>Dark Patterns</strong> oder <strong>Gamification</strong> zu bestimmten Verhaltensweisen zu bewegen.</li>
</ol>

<hr />
<h2 id="3-tugendethik-ki-und-die-kultivierung-menschlicher-exzellenz"><strong>3. Tugendethik: KI und die Kultivierung menschlicher Exzellenz</strong></h2>

<h3 id="31-aristoteles-tugendethik-im-digitalen-zeitalter"><strong>3.1 Aristoteles’ Tugendethik im digitalen Zeitalter</strong></h3>
<p>Aristoteles’ <em>Nikomachische Ethik</em> (Buch II) definiert Tugenden als <strong>dispositionale Eigenschaften</strong>, die durch <strong>Habituation</strong> erworben werden. KI stellt diese Prozesse vor neue Herausforderungen:</p>

<h4 id="311-die-tugend-der-phronesis-klugheit-in-algorithmischen-umgebungen"><strong>3.1.1 Die Tugend der <em>phronesis</em> (Klugheit) in algorithmischen Umgebungen</strong></h4>
<ul>
  <li><strong>Problem:</strong> KI-Systeme fördern oft <strong>instrumentelles Lernen</strong> („Wie löse ich diese Aufgabe?“) statt <strong>phronetischer Urteilsfähigkeit</strong> („Was ist hier die richtige Handlung?“).</li>
  <li><strong>Beispiel:</strong> Ein Chatbot, der Hausaufgaben löst, untergräbt die Entwicklung von <strong>Urteilsvermögen</strong> (Koepsell, 2019).</li>
  <li><strong>Gegenstrategie:</strong> KI sollte als <strong>„Sokratischer Partner“</strong> fungieren, der durch Fragen zur Reflexion anregt (z. B. <em>Woolf et al., 2013</em>).</li>
</ul>

<h4 id="312-ki-und-die-tugend-der-neugier"><strong>3.1.2 KI und die Tugend der Neugier</strong></h4>
<ul>
  <li><strong>Empirische Befunde:</strong>
    <ul>
      <li>Studien zeigen, dass Lernende, die mit KI-Tutoren arbeiten, <strong>weniger intrinsisch motiviert</strong> sind (Ryan &amp; Deci, 2020).</li>
      <li><strong>Ausnahme:</strong> Wenn KI <strong>offene Fragen</strong> stellt (z. B. <em>„Warum denkst du, dass diese Lösung funktioniert?“</em>), kann sie Neugier fördern (Graesser et al., 2018).</li>
    </ul>
  </li>
  <li><strong>Pädagogische Konsequenz:</strong> KI sollte <strong>kognitive Dissonanz</strong> provozieren, nicht Auflösung bieten.</li>
</ul>

<h4 id="313-soziale-tugenden-in-hybrid-sozialen-lernumgebungen"><strong>3.1.3 Soziale Tugenden in hybrid-sozialen Lernumgebungen</strong></h4>
<ul>
  <li><strong>Risiko:</strong> Wenn KI soziale Interaktion ersetzt (z. B. durch Chatbots statt Gruppendiskussionen), leiden <strong>Empathie</strong> und <strong>Kooperationsfähigkeit</strong> (Turkle, 2017).</li>
  <li><strong>Lösungsansatz:</strong> <strong>„Blended Learning“-Modelle</strong>, die KI mit sozialem Lernen kombinieren (z. B. KI-gestützte Rollenspiele mit anschließender Reflexion in der Gruppe).</li>
</ul>

<hr />
<h3 id="32-ki-als-tugend-trainer-möglichkeiten-und-grenzen"><strong>3.2 KI als „Tugend-Trainer“? Möglichkeiten und Grenzen</strong></h3>

<table>
  <thead>
    <tr>
      <th><strong>Tugend</strong></th>
      <th><strong>KI-Potenzial</strong></th>
      <th><strong>Grenzen der KI</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Neugier</strong></td>
      <td>Personalisierte Wissensangebote</td>
      <td>Kann keine echte <strong>Wissbegierde</strong> wecken</td>
    </tr>
    <tr>
      <td><strong>Kritikfähigkeit</strong></td>
      <td>Feedback auf Argumentationslücken</td>
      <td>Keine <strong>moralische Vorbildfunktion</strong></td>
    </tr>
    <tr>
      <td><strong>Geduld</strong></td>
      <td>Adaptives Tempo</td>
      <td>Keine <strong>emotionale Unterstützung</strong></td>
    </tr>
    <tr>
      <td><strong>Empathie</strong></td>
      <td>Simulation sozialer Szenarien</td>
      <td>Kein <strong>echtes Gegenüber</strong></td>
    </tr>
  </tbody>
</table>

<hr />
<h2 id="4-utilitarismus-nutzenmaximierung-zwischen-effizienz-und-gerechtigkeit"><strong>4. Utilitarismus: Nutzenmaximierung zwischen Effizienz und Gerechtigkeit</strong></h2>

<h3 id="41-quantitativer-utilitarismus-ki-als-heilsbringer-der-bildung"><strong>4.1 Quantitativer Utilitarismus: KI als Heilsbringer der Bildung?</strong></h3>
<ul>
  <li><strong>Argumente für KI:</strong>
    <ul>
      <li><strong>Effizienz:</strong> KI kann administrative Aufgaben übernehmen und Lehrkräfte entlasten (Luckin et al., 2016).</li>
      <li><strong>Skalierbarkeit:</strong> KI-Tutoren (z. B. <em>Duolingo</em>, <em>Khan Academy</em>) ermöglichen <strong>globalen Zugang</strong> zu Bildung.</li>
    </ul>
  </li>
  <li><strong>Kritik:</strong>
    <ul>
      <li><strong>„McDonaldisierung“ der Bildung</strong> (Ritzer, 2011): Standardisierung führt zu <strong>Verlust von pädagogischer Vielfalt</strong>.</li>
      <li><strong>Datenkolonialismus</strong> (Couldry &amp; Mejias, 2019): Tech-Konzerne profitieren von Lernerdaten, während Schulen abhängig werden.</li>
    </ul>
  </li>
</ul>

<h4 id="411-das-trolley-problem-der-bildungs-ki"><strong>4.1.1 Das „Trolley-Problem“ der Bildungs-KI</strong></h4>
<ul>
  <li><strong>Dilemma:</strong> Soll eine KI Ressourcen auf die <strong>Mehrheit</strong> (z. B. leistungsstarke Schüler:innen) oder auf <strong>Benachteiligte</strong> (z. B. Lernende mit Förderbedarf) konzentrieren?</li>
  <li><strong>Utilitaristische Antwort:</strong> Es kommt auf die <strong>Netto-Nutzenmaximierung</strong> an – doch wer definiert „Nutzen“?
    <ul>
      <li><strong>Ökonomische Perspektive:</strong> Höhere Abschlussquoten → bessere Arbeitsmarktchancen.</li>
      <li><strong>Pädagogische Perspektive:</strong> <strong>Bildung als Selbstzweck</strong> (Humboldt’sches Ideal) vs. <strong>Bildung als Mittel zum Zweck</strong>.</li>
    </ul>
  </li>
</ul>

<h3 id="42-qualitativer-utilitarismus-bildung-als-mehr-als-messbare-outcomes"><strong>4.2 Qualitativer Utilitarismus: Bildung als mehr als messbare Outcomes</strong></h3>
<ul>
  <li><strong>John Stuart Mills (1863) Unterscheidung zwischen „höheren“ und „niederen“ Freuden:</strong>
    <ul>
      <li>KI, die nur auf <strong>Testergebnisse</strong> optimiert, fördert <strong>niedere Freuden</strong> (z. B. Bulimie-Lernen).</li>
      <li><strong>Qualitative Ziele</strong> wie Kreativität, kritisches Denken oder demokratische Mündigkeit werden vernachlässigt.</li>
    </ul>
  </li>
  <li><strong>Forderung:</strong> KI muss <strong>langfristige gesellschaftliche Effekte</strong> berücksichtigen – nicht nur kurzfristige Lernerfolge.</li>
</ul>

<hr />
<h3 id="43-utilitarismus-in-der-praxis-wer-profitiert-wirklich"><strong>4.3 Utilitarismus in der Praxis: Wer profitiert wirklich?</strong></h3>

<table>
  <thead>
    <tr>
      <th><strong>Akteur</strong></th>
      <th><strong>Möglicher Nutzen</strong></th>
      <th><strong>Mögliche Nachteile</strong></th>
      <th><strong>Ethische Bewertung</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Lernende</strong></td>
      <td>Individuelle Förderung, schnellere Erfolge</td>
      <td>Überwachung, Stress, Verlust von Autonomie</td>
      <td>Ambivalent – hängt von der Umsetzung ab</td>
    </tr>
    <tr>
      <td><strong>Lehrkräfte</strong></td>
      <td>Entlastung, mehr Zeit für Pädagogik</td>
      <td>Dequalifizierung, Kontrolle durch Algorithmen</td>
      <td>Positiv, wenn partizipativ gestaltet</td>
    </tr>
    <tr>
      <td><strong>Schulsystem</strong></td>
      <td>Kostensenkung, höhere Abschlussquoten</td>
      <td>Standardisierung, Verlust von Vielfalt</td>
      <td>Kritisch – Risiko der Zweckentfremdung</td>
    </tr>
    <tr>
      <td><strong>Tech-Unternehmen</strong></td>
      <td>Profit durch Daten, Marktmacht</td>
      <td>Ethische Verantwortungsdiffusion</td>
      <td>Problematisch – Konflikt mit Bildungszielen</td>
    </tr>
  </tbody>
</table>

<hr />
<h2 id="5-synthese-ein-pluriperspektivischer-ethischer-rahmen-für-ki-in-der-bildung"><strong>5. Synthese: Ein pluriperspektivischer ethischer Rahmen für KI in der Bildung</strong></h2>

<table>
  <thead>
    <tr>
      <th><strong>Ethische Perspektive</strong></th>
      <th><strong>Zentrale Forderung</strong></th>
      <th><strong>Kritische Einwände</strong></th>
      <th><strong>Praktische Umsetzung</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Deontologie</strong></td>
      <td>Autonomie, Transparenz, guter Wille, Verantwortung</td>
      <td>Zu starr für komplexe Bildungskontexte?</td>
      <td>Ethische Richtlinien, partizipative Gestaltung</td>
    </tr>
    <tr>
      <td><strong>Tugendethik</strong></td>
      <td>Förderung von <em>phronesis</em>, Neugier, Empathie</td>
      <td>Wie misst man Tugenden?</td>
      <td>KI als „Sokratischer Partner“, Blended Learning</td>
    </tr>
    <tr>
      <td><strong>Utilitarismus</strong></td>
      <td>Nutzenmaximierung für alle</td>
      <td>Wer definiert „Nutzen“?</td>
      <td>Langfristige Nutzenanalyse, Regulierung</td>
    </tr>
  </tbody>
</table>

<hr />
<h2 id="6-fazit-ki-in-der-bildung-als-gesellschaftliche-gestaltungsaufgabe"><strong>6. Fazit: KI in der Bildung als gesellschaftliche Gestaltungsaufgabe</strong></h2>
<p>Die ethische Bewertung von KI in der Bildung erfordert einen <strong>pluriperspektivischen Ansatz</strong>, der:</p>
<ol>
  <li><strong>Deontologische Prinzipien</strong> (Würde, Autonomie, guter Wille) als <strong>nicht verhandelbare Grenzen</strong> setzt.</li>
  <li><strong>Tugendethische Ziele</strong> (mündige, kritische Bürger:innen) in den Mittelpunkt stellt.</li>
  <li><strong>Utilitaristische Abwägungen</strong> transparent und partizipativ gestaltet.</li>
</ol>

<h3 id="61-drei-dringende-handlungsfelder"><strong>6.1 Drei dringende Handlungsfelder</strong></h3>
<ol>
  <li><strong>Regulatorisch:</strong>
    <ul>
      <li><strong>Verbindliche Ethik-Richtlinien</strong> für KI in Schulen (vgl. <em>EU AI Act</em>).</li>
      <li><strong>Unabhängige Auditierung</strong> von Bildungs-KI auf Bias und Manipulationspotenzial.</li>
    </ul>
  </li>
  <li><strong>Pädagogisch:</strong>
    <ul>
      <li><strong>Kritische KI-Bildung</strong> als Pflichtfach – Lernende müssen verstehen, wie Algorithmen funktionieren.</li>
      <li><strong>Lehrkräftefortbildungen</strong> zu ethischen Dilemmata der KI-Nutzung.</li>
    </ul>
  </li>
  <li><strong>Technologisch:</strong>
    <ul>
      <li><strong>Open-Source-Alternativen</strong> zu kommerziellen KI-Tools (z. B. <em>Moodle</em>-Plug-ins statt <em>Blackboard</em>).</li>
      <li><strong>„Human-in-the-Loop“-Systeme</strong>, die Lehrkräfte nicht ersetzen, sondern unterstützen.</li>
    </ul>
  </li>
</ol>

<hr />
<h3 id="62-offene-forschungsfragen"><strong>6.2 Offene Forschungsfragen</strong></h3>
<ol>
  <li>Wie kann KI <strong>Bildungsgerechtigkeit</strong> fördern, ohne neue Ungleichheiten zu schaffen?</li>
  <li>Lässt sich <strong>Aristotelische Tugendethik</strong> in digitalen Lernumgebungen überhaupt umsetzen?</li>
  <li>Brauchen wir ein <strong>neues Menschenbild</strong> für das Zeitalter der KI-Bildung?</li>
</ol>

<hr />
<h3 id="63-provokante-these-zur-diskussion"><strong>6.3 Provokante These zur Diskussion</strong></h3>
<p><em>„Wenn KI in 20 Jahren die meisten Lehrkräfte ersetzt hat, wird das weniger ein technologisches als ein politisches Versagen sein – nämlich das Versagen, Bildung als öffentlichen Raum der Begegnung und des Streitens zu verteidigen.“</em></p>

<hr />
<h3 id="diskussionsfragen-für-leserinnen"><strong>Diskussionsfragen für Leser:innen</strong></h3>
<ol>
  <li><strong>Deontologisch:</strong> Dürfen Schulen KI-Systeme einsetzen, die Lernende nicht vollständig verstehen können – oder verstößt das gegen Kants Prinzip der Aufklärung?</li>
  <li><strong>Tugendethisch:</strong> Kann KI jemals mehr sein als ein „Werkzeug“ – oder bleibt sie immer ein <strong>„tugendloses“ Medium</strong>?</li>
  <li><strong>Utilitaristisch:</strong> Ist es vertretbar, KI in Schulen einzuführen, wenn sie <strong>kurzfristig</strong> die Lernergebnisse verbessert, aber <strong>langfristig</strong> die kritische Urteilsfähigkeit schwächt?</li>
</ol>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2025-11-26T10:08:03+00:00">November 26, 2025</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/ki-wiki-25-26/seite2/" class="pagination--pager" title="Seite 2
">Previous</a>
    
    
      <a href="/ki-wiki-25-26/prompt_engineering/" class="pagination--pager" title="Prompt Engineering
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/ki-wiki-25-26/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 ki-wiki. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/ki-wiki-25-26/assets/js/main.min.js"></script>




<script src="/ki-wiki-25-26/assets/js/lunr/lunr.min.js"></script>
<script src="/ki-wiki-25-26/assets/js/lunr/lunr-store.js"></script>
<script src="/ki-wiki-25-26/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
