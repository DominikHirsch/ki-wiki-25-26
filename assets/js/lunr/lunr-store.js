var store = [{
        "title": "Unterseite 1",
        "excerpt":"Das ist die erste Unterseite von Seite 2.  ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/seite2/sub1/",
        "teaser": null
      },{
        "title": "Unterseite 2",
        "excerpt":"Das ist die zweite Unterseite von Seite 2.  ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/seite2/sub2/",
        "teaser": null
      },{
        "title": "KI Heute",
        "excerpt":"KI Heute   Künstliche Intelligenz (KI) im Jahr 2025/2026 ist geprägt von rasanten Fortschritten in Modellarchitekturen, Anwendungsbreite und gesellschaftlichen Debatten. Dieser Artikel gibt einen Überblick über aktuelle Trends, Technologien und Herausforderungen.     1. Aktuelle Schlüsseltechnologien   Generative KI     Große Sprachmodelle (LLMs): Modelle wie Mistral AI, GPT-4 oder Llama 3 generieren kontextuell präzise Texte, Code und multimodale Inhalte (Text+Bild+Audio).            Beispielanwendungen: Chatbots, automatisierte Content-Erstellung, Programmierung (z. B. GitHub Copilot).       Herausforderung: „Halluzinationen“ (falsche Fakten) und Urheberrechtsfragen (EU AI Act, 2024).           Diffusionsmodelle: KI wie Stable Diffusion oder Midjourney erzeugen Bilder/Videos aus Textprompts.            Ethische Debatte: Deepfakes, Kunsturheberrecht (z. B. Klage von Getty Images gegen Stability AI, 2023).           Edge AI &amp; Effizienz     Lokale KI-Modelle: Kleinere Modelle (z. B. Mistral 7B, Phi-3) laufen auf Smartphones oder Raspberry Pis – Datenschutzvorteil durch On-Device-Verarbeitung.   Anwendungen: Echtzeit-Übersetzung (z. B. Google Pixel), Gesundheitsmonitoring.     2. Anwendungsbereiche (Auswahl)                  Bereich       Beispiele       Herausforderungen                       Bildung       Adaptive Lernplattformen (z. B. Khanmigo), KI-Tutoren       „Bias“ in Lehrinhalten, Abhängigkeit                 Medizin       KI-gestützte Diagnostik (z. B. IBM Watson Health), Drug Discovery       Haftungsfragen, Datenqualität                 Industrie       Predictive Maintenance, autonome Roboter (z. B. Tesla Optimus)       Arbeitsplatzveränderungen                 Kreativität       KI-Musik (z. B. Suno), Drehbücher (z. B. „The Frost“ mit KI-Unterstützung)       Urheberrecht, „menschliche Note“             3. Gesellschaftliche und ethische Fragen   Regulierung     EU AI Act (2024): Klassifiziert KI-Systeme nach Risiko (von „minimal“ bis „inakzeptabel“).            Verboten: Soziales Scoring (wie in China), manipulative KI.       Transparenzpflicht: Kennzeichnung von KI-generierten Inhalten (z. B. bei Deepfakes).           USA &amp; China: USA: Fokus auf „AI Bill of Rights“ (2023) für Nicht-Diskriminierung. China: Staatliche Kontrolle über KI-Entwicklung (z. B. Zensur von LLMs).   Umweltimpact     Ressourcenverbrauch: Training von LLMs verbraucht massive Energie (z. B. GPT-4: ~500 MWh).            Lösungsansätze: „Green AI“ (effizientere Modelle), CO₂-Kompensation (z. B. bei Hugging Face).           Arbeitsmarkt     Automatisierung: KI ersetzt repetitive Jobs (z. B. Datenanalyse, Kundenservice), schafft aber neue Rollen (z. B. „Prompt Engineer“).            Studie: Bis 2030 könnten 30% der Tätigkeiten in 60% der Berufe automatisiert werden (McKinsey, 2023).             4. Kritische Perspektiven   Hype vs. Realität     Überbewertung: Medien berichten oft unkritisch über KI („AGI ist nah“), während Experten (z. B. Yann LeCun) betonen, dass aktuelle KI keine Allgemeinintelligenz besitzt.   Begrenzungen:            Kein kausales Verständnis (KI erkennt Muster, versteht aber nicht warum).       Abhängigkeit von Trainingsdaten (z. B. rassistische Bias in Gesichtsrekennung).           Soziale Ungleichheit     Zugang: Hochwertige KI-Tools sind oft teuer (z. B. Closed-Source-APIs) oder erfordern technische Expertise.   Datenkolonialismus: Unternehmen des Globalen Nordens nutzen Daten aus dem Globalen Süden ohne Kompensation.     5. Quellen und Weiterführendes   Quellen     EU AI Act: Offizieller Text (2024)   McKinsey-Studie: „The future of work“ (2023)   Getty vs. Stability AI: The Verge (2023)   Vertiefung     Bücher: „Atlas of AI“ (Kate Crawford), „Rebooting AI“ (Gary Marcus)   Dokumentationen: „The Social Dilemma“ (Netflix), „iHuman“ (2019)   Kritische Stimmen: AI Now Institute, DAIR Institute    Diskussionsfragen für Studierende:     Sollte KI-generierter Content immer gekennzeichnet werden? Warum (nicht)?   Wie kann „Bias in KI“ im Bildungsbereich aktiv vermieden werden?   Ist der EU AI Act ein Vorbild für globale Regulierung – oder bremst er Innovation?    Hinweis: Dieser Artikel ist als Grundgerüst gedacht. Ergänzt ihn mit:     Aktuellen Beispielen (z. B. KI-Tools wie Perplexity oder Midjourney V6).   Lokale Bezüge (z. B. KI-Forschung an der Uni Heidelberg).   Eigene Analysen (z. B. Vergleich mit KI-Geschichte).   Letzte Aktualisierung: November 2025  ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/ki-heute/",
        "teaser": null
      },{
        "title": "Seite 1",
        "excerpt":"Dies ist Seite 1 im Wiki. Seite 1 hat keine weiteren Unterseiten.   ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/seite1/",
        "teaser": null
      },{
        "title": "Seite 2",
        "excerpt":"Dies ist Seite 2 im Wiki.  Sie hat zwei Unterseiten.  ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/seite2/",
        "teaser": null
      },{
        "title": "Philosophische-reflexion",
        "excerpt":"Künstliche Intelligenz in der Bildung: Eine vertiefte ethisch-philosophische Analyse     Einleitung: Warum die Ethik der KI-Bildung mehr ist als eine technische Debatte   Die Integration von KI in Bildungsprozesse ist kein neutraler technologischer Fortschritt, sondern ein ethisches Experimentierfeld. Sie berührt Grundfragen des Menschseins:     Was bedeutet Lernen?   Wie viel Autonomie sind wir bereit aufzugeben?   Wem vertrauen wir die Gestaltung von Wissen an?     1. Deontologie: KI zwischen Pflicht und Überwachung   a) Kants kategorischer Imperativ im digitalen Klassenzimmer   Die Deontologie fragt: Darf KI überhaupt in Bildungsprozessen eingesetzt werden, wenn sie grundlegende moralische Prinzipien verletzt?   Drei zentrale Konflikte:                  Problem       Beispiel       Lösung?                       Autonomie vs. Algorithmen       KI entscheidet über Lerninhalte und schränkt Selbstbestimmung ein.       Transparente Algorithmen mit Widerspruchsmöglichkeiten.                 Verantwortungsdiffusion       Wer haftet bei diskriminierenden KI-Entscheidungen?       Klare Rechenschaftspflicht für Schulen und Tech-Unternehmen.                 Datenschutz       Sensible Lernprofile könnten missbraucht werden.       Strenge Datenschutzrichtlinien und Anonymisierung.             b) Praktische Implikationen für Schulen      Ethische Richtlinien: Schulen benötigen verbindliche KI-Ethik-Codes.   Partizipation: Lernende und Lehrkräfte müssen als Mitgestalter einbezogen werden.     2. Tugendethik: KI als Herausforderung für die menschliche Entwicklung   a) Aristoteles im Zeitalter der Algorithmen   Die Tugendethik fragt: Trägt KI dazu bei, dass Lernende zu „guten Menschen“ werden?   Risiken und Gegenstrategien:                  Tugend       Risiko durch KI       Gegenstrategie                       Neugier       KI liefert Antworten, bevor Fragen gestellt werden.       KI sollte Fragen provozieren, nicht Antworten liefern.                 Kritikfähigkeit       Lernende akzeptieren KI als unfehlbare Autorität.       KI sollte Fehler offenlegen und zum Hinterfragen anregen.                 Empathie       Soziale Interaktion wird durch Chatbots ersetzt.       KI sollte soziale Lernformate unterstützen, nicht ersetzen.             b) KI als „Tugend-Trainer“?      Vision: KI könnte Tugenden fördern, indem sie:            Reflexionsfragen stellt (z. B.: „Was hast du aus diesem Fehler gelernt?“).       Feedback auf soziales Verhalten gibt (z. B. in Rollenspielen).           Grenze: Tugenden entstehen durch menschliche Vorbilder – KI kann sie nur anregen.     3. Utilitarismus: Nutzenmaximierung – aber für wen?   a) Quantitativer Utilitarismus: Effizienz um jeden Preis?      Messbare Vorteile:            Höhere Lernerfolge durch personalisierte Wiederholungen.       Entlastung von Lehrkräften.           Nicht messbare Kosten:            Stress durch ständige Leistungsüberwachung.       Verlust von Kreativität.             b) Qualitativer Utilitarismus: Bildung als mehr als Datenpunkte                  Akteur       Möglicher Nutzen       Mögliche Nachteile                       Lernende       Individuelle Förderung, schnellere Erfolge       Überwachung, Stress, Verlust von Kreativität                 Lehrkräfte       Entlastung, mehr Zeit für Pädagogik       Abhängigkeit von Technologie, Dequalifizierung                 Schulsystem       Höhere Abschlussquoten, Kostensenkung       Standardisierung, Verlust von Vielfalt                 Tech-Unternehmen       Profit durch Daten, Marktmacht       Ethische Verantwortungsdiffusion             c) Utilitarismus in der Praxis      Forderung: KI muss allen nützen – nicht nur einer Minderheit.   Umsetzung:            Regulatorische Eingriffe.       Langfristige Nutzenanalyse.             Synthese: Ein ethischer Rahmen für KI in der Bildung                  Ethische Perspektive       Zentrale Forderung       Umsetzung in der Praxis                       Deontologie       Autonomie, Transparenz, Gerechtigkeit       Ethische Richtlinien, partizipative Gestaltung                 Tugendethik       Förderung von Neugier, Kritikfähigkeit, Empathie       KI als „Tugend-Trainer“, nicht als Ersatz                 Utilitarismus       Nutzenmaximierung für alle       Regulierung, langfristige Nutzenanalyse             Ausblick: KI als Spiegel unserer Bildungsziele   Die Debatte um KI in der Bildung ist eine Debatte über unsere Werte:     Deontologisch: Dürfen wir KI einsetzen, ohne Autonomie zu opfern?   Tugendethisch: Macht KI uns zu besseren Menschen?   Utilitaristisch: Nutzt KI der Gesellschaft – oder nur einigen?   Drei konkrete Handlungsempfehlungen:     Ethische Bildung als Pflichtfach.   Demokratische Kontrolle über KI-Systeme.   Mensch im Mittelpunkt: KI sollte unterstützen, nicht ersetzen.     Diskussionsfrage:  Wenn KI in 20 Jahren die meisten Lehrkräfte ersetzt hat – was haben wir dann gewonnen? Und was unwiederbringlich verloren?  ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/philosophische-reflexion/",
        "teaser": null
      },{
        "title": "Soziologische Perspektive",
        "excerpt":"Soziologische Perspektiven auf Künstliche Intelligenz     1. KI als soziales Phänomen   1.1 Definition und gesellschaftliche Einbettung   Künstliche Intelligenz (KI) wird in der Soziologie nicht als isolierte Technologie, sondern als soziotechnisches System analysiert. Sie entsteht im Kontext sozialer Praktiken, Institutionen und Machtverhältnisse. Die Soziologie fragt:      Konstruktion von KI: Wie wird KI in verschiedenen gesellschaftlichen Bereichen (Wirtschaft, Politik, Kultur) interpretiert, entwickelt und genutzt? Welche Akteure (Tech-Konzerne, Staaten, NGOs, Nutzer:innen) gestalten diese Prozesse?   Soziale Praktiken: Wie verändern sich Alltagsroutinen, Arbeitsprozesse und Kommunikationsformen durch den Einsatz von KI? (z.B. Sprachassistenten, Empfehlungssysteme, autonome Fahrzeuge)   Institutionelle Einbettung: Wie wird KI in bestehende Institutionen (Schulen, Krankenhäuser, Behörden) integriert? Welche neuen Institutionen entstehen (z.B. Ethik-Beiräte, Regulierungsbehörden)?   Beispiel: Die Entwicklung von KI-Systemen für die Personalauswahl ist nicht nur eine technische Herausforderung, sondern auch ein sozialer Aushandlungsprozess zwischen Arbeitgeber:innen, Arbeitnehmer:innen, Gewerkschaften und Gesetzgeber:innen.     1.2 KI und soziale Ungleichheit   KI-Systeme sind nicht neutral, sondern reproduzieren und verstärken oft bestehende soziale Ungleichheiten. Zentrale Aspekte:      Algorithmen und Diskriminierung: KI-Systeme können Vorurteile und Diskriminierung reproduzieren, wenn sie auf verzerrten Daten basieren. Beispiele:            Personalauswahl: Algorithmen, die auf historischen Bewerbungsdaten trainiert werden, können Frauen oder Minderheiten benachteiligen.       Kreditvergabe: KI-Systeme können bestimmte Bevölkerungsgruppen aufgrund von Wohnort, Ethnie oder Geschlecht systematisch ausschließen.       Strafjustiz: Predictive Policing-Algorithmen können rassistische Polizeipraktiken verstärken, indem sie bestimmte Stadtteile oder Gruppen als „risikoreich“ einstufen.           Zugang und Macht:            Digitale Kluft: Wer hat Zugang zu KI-Technologien? Wer kann sie entwickeln, nutzen und kontrollieren? Die Ungleichheit im Zugang zu digitalen Ressourcen wird durch KI weiter vertieft.       Machtkonzentration: KI wird zunehmend von wenigen Tech-Konzernen (Google, Meta, Microsoft, Amazon) dominiert, was zu neuen Abhängigkeiten und Monopolen führt.       Arbeitsmarkt: KI führt zu einer Polarisierung der Arbeitswelt – hochqualifizierte Jobs profitieren, während einfache Tätigkeiten automatisiert werden.           Beispiel: Studien zeigen, dass Gesichtserkennungssoftware bei Menschen mit dunkler Hautfarbe häufiger Fehler macht, was auf unausgewogene Trainingsdaten zurückzuführen ist.     2. Theoretische Perspektiven der Soziologie auf KI     2.1 Strukturfunktionalismus   Der Strukturfunktionalismus betrachtet KI als Funktionssystem, das zur Stabilität und Effizienz moderner Gesellschaften beiträgt.      Funktion von KI in sozialen Systemen:            Wirtschaft: KI steigert die Produktivität durch Automatisierung und Optimierung (z.B. Logistik, Produktion, Dienstleistungen).       Bildung: Adaptive Lernsysteme ermöglichen individualisierte Bildung.       Gesundheit: KI unterstützt Diagnostik, Therapieplanung und Pflege.           Systemintegration:            KI kann soziale Systeme stabilisieren, indem sie komplexe Prozesse vereinfacht und beschleunigt.       Gleichzeitig schafft sie neue Abhängigkeiten (z.B. von Tech-Konzernen oder staatlichen Überwachungssystemen).           Kritik: Der Strukturfunktionalismus vernachlässigt Machtungleichheiten und Konflikte, die durch KI entstehen können.     2.2 Konfliktsoziologie   Die Konfliktsoziologie analysiert KI als Instrument und Gegenstand sozialer Konflikte.      Macht und Kontrolle:            Überwachung: KI ermöglicht neue Formen der sozialen Kontrolle (z.B. Predictive Policing, Social Scoring in China).       Arbeitskonflikte: KI führt zu Arbeitsplatzverlusten und Prekarisierung, aber auch zu neuen Formen der Arbeitsorganisation (z.B. Plattformarbeit).           Interessenskonflikte:            Arbeit vs. Kapital: Während Unternehmen durch KI Kosten sparen, stehen Arbeitnehmer:innen vor Jobverlust oder Umqualifizierung.       Staat vs. Bürger:innen: KI-gestützte Überwachung (z.B. Gesichtserkennung) führt zu Konflikten um Privatsphäre und Grundrechte.           Beispiel: Die Einführung von KI in der Logistik (z.B. bei Amazon) führt zu einer Intensivierung der Arbeit und einer Zunahme von Überwachung, was zu Arbeitskämpfen und Protesten führt.     2.3 Symbolischer Interaktionismus   Der Symbolische Interaktionismus untersucht, wie Menschen KI deuten, nutzen und in ihre Alltagswelt integrieren.      Mensch-KI-Interaktion:            Wie kommunizieren Menschen mit KI-Systemen (z.B. Chatbots, Sprachassistenten)? Welche Erwartungen und Zuschreibungen entwickeln sie?       Wie verändert sich die zwischenmenschliche Kommunikation durch KI (z.B. Deepfakes, synthetische Stimmen)?           Identität und Agency:            Werden KI-Systeme als „soziale Akteure“ wahrgenommen? (z.B. Roboter in der Pflege, virtuelle Influencer:innen)       Wie verändert sich das Verständnis von Menschlichkeit, wenn Maschinen „menschliche“ Eigenschaften simulieren?           Beispiel: Studien zeigen, dass Nutzer:innen von Sprachassistenten (wie Alexa oder Siri) diesen oft menschliche Eigenschaften zuschreiben und emotional auf sie reagieren.     2.4 Kritische Theorie   Die Kritische Theorie analysiert KI als Instrument der Herrschaft und Entmündigung, aber auch als mögliches Werkzeug der Emanzipation.      Ideologiekritik:            KI wird oft als „neutral“ oder „objektiv“ dargestellt, obwohl sie gesellschaftliche Machtverhältnisse reproduziert.       KI dient der Rationalisierung und Ökonomisierung sozialer Bereiche (z.B. Bildung, Gesundheit).           Emanzipatorisches Potenzial:            KI kann zur Demokratisierung von Wissen beitragen (z.B. offene KI-Tools, Bürgerwissenschaft).       KI kann marginalisierte Gruppen stärken (z.B. durch barrierefreie Technologien).           Beispiel: KI-gestützte Übersetzungsdienste können Migrant:innen den Zugang zu Informationen erleichtern, gleichzeitig können sie aber auch zur Überwachung und Kontrolle genutzt werden.     2.5 Akteur-Netzwerk-Theorie (ANT)   Die ANT betrachtet KI als nicht-menschlichen Akteur, der in Netzwerken von Menschen, Technologien und Institutionen handelt.      KI als Akteur:            Algorithmen und KI-Systeme entfalten Handlungsmacht, indem sie Entscheidungen treffen, Ressourcen verteilen und soziale Realitäten gestalten.       Beispiel: Ein Algorithmus, der über Kreditvergaben entscheidet, hat direkte Auswirkungen auf die Lebenschanen von Menschen.           Netzwerke der KI:            KI entsteht nicht im luftenleeren Raum, sondern in komplexen Netzwerken aus Entwickler:innen, Nutzer:innen, Daten, Hardware und Regulierungsinstanzen.           Beispiel: Die Entwicklung eines KI-Systems für die medizinische Diagnostik umfasst Ärzt:innen, Programmierer:innen, Krankenhäuser, Patientenorganisationen und Gesundheitsbehörden – alle sind Teil des „Akteur-Netzwerks“.     2.6 Poststrukturalismus und Posthumanismus   Poststrukturalistische und posthumanistische Ansätze hinterfragen traditionelle Vorstellungen von Subjektivität, Autonomie und Mensch-Maschine-Grenzen.      Dekonstruktion von Subjektivität:            KI stellt die Idee des „autonomen Subjekts“ infrage, da Entscheidungen zunehmend von Algorithmen getroffen werden.       Beispiel: Autonome Waffen oder selbstlernende Systeme werfen Fragen nach Verantwortung und Agency auf.           Cyborgisierung:            Die Grenzen zwischen Mensch und Maschine verschwimmen (vgl. Donna Haraways „Cyborg-Manifest“).       Beispiel: Brain-Computer-Interfaces oder Prothesen, die durch KI gesteuert werden.           Beispiel: Künstler:innen nutzen KI, um neue Formen von Kunst zu schaffen, die die Grenzen zwischen menschlicher Kreativität und maschineller Generierung verwischen.     3. Zentrale Debatten und Forschungsfelder     3.1 Arbeit und Ökonomie      Automatisierung und Arbeitsmarkt:            Jobverluste: KI und Robotik ersetzen Routinetätigkeiten (z.B. in der Produktion, im Dienstleistungssektor).       Neue Berufsfelder: Gleichzeitig entstehen neue Jobs in der KI-Entwicklung, Datenanalyse und -kuratierung.           Plattformökonomie:            KI ist ein zentraler Treiber der Gig-Economy (z.B. Uber, Lieferdienste), die oft prekäre Arbeitsverhältnisse schafft.       Algorithmen steuern Arbeitsprozesse, bewerten Leistung und disziplinieren Arbeitnehmer:innen.           Beispiel: In Amazon-Lagern werden Arbeiter:innen durch KI-gestützte Systeme überwacht und ihre Leistung in Echtzeit bewertet.     3.2 Überwachung und Privatsphäre      Surveillance Capitalism (Shoshana Zuboff):            Tech-Konzerne nutzen KI, um Nutzerdaten zu sammeln, zu analysieren und zu monetarisieren.       Beispiel: Personalisierte Werbung, die auf detaillierten Profilen basiert.           Soziale Sortierung:            Algorithmen klassifizieren und bewerten Individuen (z.B. Kredit-Scoring, Versicherungsalgorithmen).       Beispiel: In China wird ein „Social Credit System“ erprobt, das das Verhalten von Bürger:innen bewertet und belohnt oder bestraft.             3.3 Kultur und Medien      KI und kulturelle Produktion:            KI verändert die Erstellung und Rezeption von Kunst, Musik und Literatur (z.B. generative KI wie DALL-E, Midjourney).       Beispiel: KI-generierte Musik oder Texte werfen Fragen nach Urheberschaft und Originalität auf.           Mediennutzung:            KI personalisiert Inhalte und schafft Filterblasen und Echo-Kammern.       Beispiel: Soziale Medien nutzen KI, um Nutzer:innen gezielt mit Inhalten zu versorgen, die ihre bestehenden Meinungen verstärken.             3.4 Ethik und Regulierung      Algorithmenethik:            Wie können KI-Systeme fair, transparent und verantwortungsvoll gestaltet werden?       Beispiel: Die EU fordert „explainable AI“, also KI-Systeme, deren Entscheidungen nachvollziehbar sind.           Regulierungsdebatten:            Braucht es eine „KI-Gesetzgebung“? (vgl. EU AI Act, der KI-Systeme nach Risikostufen reguliert)       Beispiel: In der EU werden hochriskante KI-Anwendungen (z.B. in der Strafjustiz) strengeren Regeln unterworfen.             3.5 Bildung und Sozialisation      KI in der Bildung:            Adaptive Lernsysteme passen sich den Bedürfnissen von Lernenden an, bergen aber auch Risiken der Standardisierung und Entmündigung.       Beispiel: KI-Tutoren können individuell fördern, aber auch Lernprozesse kontrollieren und bewerten.           Sozialisation durch KI:            Wie prägen KI-Systeme (z.B. Sprachassistenten, soziale Roboter) die Sozialisation von Kindern und Jugendlichen?       Beispiel: Kinder, die mit Sprachassistenten aufwachsen, entwickeln möglicherweise andere Kommunikationsmuster als frühere Generationen.             3.6 Politik und Demokratie      KI und politische Meinungsbildung:            Deepfakes und Social Bots können öffentliche Diskurse manipulieren.       Beispiel: Im US-Wahlkampf 2020 wurden Deepfakes genutzt, um Politiker:innen in falschem Licht darzustellen.           Partizipation:            Kann KI demokratische Prozesse unterstützen (z.B. durch partizipative Algorithmen oder digitale Bürgerbeteiligung)?       Beispiel: In Taiwan wird KI genutzt, um Bürger:innen in politische Entscheidungsprozesse einzubinden.             4. Empirische Forschungsansätze     4.1 Qualitative Studien      Ethnografische Forschung:            Untersuchung der Nutzung von KI in Alltagskontexten (z.B. in Pflege, Bildung, Arbeitswelt).       Beispiel: Wie nutzen Pflegekräfte KI-gestützte Diagnosehilfen im Krankenhausalltag?           Diskursanalyse:            Wie wird KI in Medien, Politik und Wissenschaft diskutiert? Welche Narrative dominieren (z.B. „KI als Bedrohung“ vs. „KI als Chance“)?       Beispiel: Medienanalysen zeigen, dass KI oft entweder als „Retterin“ oder als „Apokalypse“ dargestellt wird.             4.2 Quantitative Studien      Survey-Forschung:            Einstellungen und Ängste der Bevölkerung gegenüber KI (z.B. Vertrauen, Akzeptanz, Sorgen um Datenschutz).       Beispiel: Umfragen zeigen, dass viele Menschen KI im Gesundheitsbereich skeptisch gegenüberstehen.           Netzwerkanalysen:            Wie verbreiten sich KI-Technologien in sozialen Netzwerken? Wer sind die zentralen Akteure?       Beispiel: Die Diffusion von KI-Tools in Unternehmen hängt oft von „Innovator:innen“ und „Early Adopters“ ab.             5. Aktuelle Strömungen und Zukunftsfragen     5.1 KI und Nachhaltigkeit      Ressourcenverbrauch:            KI-Systeme benötigen enorme Rechenleistung und Energie (z.B. Training großer Sprachmodelle).       Beispiel: Das Training eines einzigen KI-Modells kann so viel CO2 verursachen wie mehrere Autos in ihrem gesamten Lebenszyklus.           KI für Klimaschutz:            KI kann zur Optimierung von Energieverbrauch, Verkehr oder Landwirtschaft beitragen.       Beispiel: KI-gestützte Wettermodelle helfen, Extremwetterereignisse vorherzusagen.             5.2 KI und Globalisierung      KI als globaler Machtfaktor:            Wer setzt die Standards? (USA, China, EU)       Beispiel: China nutzt KI für staatliche Überwachung, während die USA auf privatwirtschaftliche Innovation setzen.           Kulturelle Unterschiede:            Wie wird KI in verschiedenen Kulturen wahrgenommen und genutzt?       Beispiel: In Japan werden soziale Roboter in der Pflege akzeptiert, während sie in Europa oft auf Skepsis stoßen.             5.3 KI und Sozialtheorie      Neue Theorien:            Braucht die Soziologie neue Konzepte, um KI zu verstehen? (z.B. „Algorithmic Governance“, „Datafizierung“)       Beispiel: Der Begriff „Datafizierung“ beschreibt, wie soziale Phänomene zunehmend in Daten übersetzt und durch Algorithmen gesteuert werden.           Interdisziplinäre Ansätze:            Verbindung von Soziologie, Informatik, Ethik und Rechtswissenschaft.       Beispiel: Die „Critical Algorithm Studies“ untersuchen die sozialen Auswirkungen von Algorithmen aus verschiedenen Perspektiven.             6. Literatur und weiterführende Quellen      Zuboff, Shoshana: The Age of Surveillance Capitalism. PublicAffairs, 2019.   Brynjolfsson, Erik / McAfee, Andrew: Machine, Platform, Crowd: Harnessing Our Digital Future. W. W. Norton &amp; Company, 2017.   Latour, Bruno: Reassembling the Social: An Introduction to Actor-Network-Theory. Oxford University Press, 2005.   Haraway, Donna: A Cyborg Manifesto: Science, Technology, and Socialist-Feminism in the Late Twentieth Century. 1985.   Couldry, Nick / Mejias, Ulises A.: The Costs of Connection: How Data Is Colonizing Human Life and Appropriating It for Capitalism. Stanford University Press, 2019.   Noble, Safiya Umoja: Algorithms of Oppression: How Search Engines Reinforce Racism. NYU Press, 2018.     Fazit   Die soziologische Auseinandersetzung mit KI zeigt, dass es sich um ein vielschichtiges Phänomen handelt, das technische, ökonomische, kulturelle und politische Dimensionen umfasst. KI ist nicht nur ein Werkzeug, sondern ein Spiegel und Gestalter gesellschaftlicher Verhältnisse. Die Soziologie leistet einen wichtigen Beitrag, um die sozialen Implikationen von KI zu verstehen, kritisch zu reflektieren und gestalterisch zu begleiten.     ","categories": [],
        "tags": [],
        "url": "/ki-wiki-25-26/Soziologische_Perspektive/",
        "teaser": null
      },]
